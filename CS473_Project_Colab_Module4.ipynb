{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Setup\n",
    "*   Clone the repo that contains all necessary files\n",
    "*   Install and set up all necessary packages\n",
    "*   Import all required libraries\n",
    "*   Import Dataset (from Roboflow)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "wb2N_1B-RRjF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Team's git repo with all files\n",
    "# !git clone --quiet https://github.com/AnvitSinha/CS473_ERD_Clustering.git\n",
    "!git clone --quiet -b stage2 https://github.com/AnvitSinha/CS473_ERD_Clustering.git\n",
    "\n",
    "# move all files to content/\n",
    "!mv CS473_ERD_Clustering/* /content/\n",
    "\n",
    "# remove temp folder\n",
    "!rm -r CS473_ERD_Clustering/"
   ],
   "metadata": {
    "id": "9H__W_8ngqyw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw4J2FKqDGvD"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# necessary installs\n",
    "!pip --quiet install roboflow\n",
    "!pip --quiet install pyyaml\n",
    "!pip --quiet install editdistance\n",
    "!pip --quiet install easyocr\n",
    "\n",
    "# set up yolo\n",
    "!git clone --quiet https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "%pip --quiet install -qr requirements.txt\n",
    "%cd ..\n",
    "\n",
    "# necessary imports\n",
    "import os\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# get data from roboflow\n",
    "rf = Roboflow(api_key=\"3kZUcOURZwpHNUXrVRYO\")\n",
    "project = rf.workspace(\"cs473-proj\").project(\"cs473-proj1\")\n",
    "dataset = project.version(5).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Directory Structure Setup\n",
    "*   Unzip all required files to their relevant directories\n",
    "*   This step assumes that pwd=/content and all zip files are present in the pwd.\n",
    "\n"
   ],
   "metadata": {
    "id": "eFCLnkI7Rpa0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure Paths\n",
    "*   Set global paths that will be utilized throughout the program\n",
    "*   All of these can be changed, but are set to work directly out of the box if the README instructions are followed\n",
    "\n"
   ],
   "metadata": {
    "id": "azGF2tNBR9KS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Configure Paths - Change any as needed\n",
    "\n",
    "# directory as described in Campuswire #308\n",
    "GRADING_DIR = \"/content/grading/\"\n",
    "\n",
    "# directory where all processed image information will be saved\n",
    "PROCESSED_DIR = \"/content/processed/\"\n",
    "\n",
    "# Path to where yolov5 is stored\n",
    "YOLO_PATH = \"/content/yolov5/\"\n",
    "\n",
    "# Directory for Model Weights\n",
    "MODEL_DIR = \"/content/model_weights\"\n",
    "\n",
    "# Path to model weights\"\n",
    "MODEL_WEIGHTS = os.path.join(MODEL_DIR, \"best.pt\")\n",
    "\n",
    "# Path to final result directory\n",
    "RESULT_DIR = \"/content/ocr_results\"\n",
    "\n",
    "# YAML Source for Class names\n",
    "YAML_PATH = \"/content/CS473-Proj1-5/data.yaml\"\n",
    "\n",
    "# Directory to store edit distance results\n",
    "EDIST_PATH = \"/content/edit_dist\"\n",
    "\n",
    "# Final directory to store txt files for submission\n",
    "SUBMIT_PATH = \"/content/submit\"\n",
    "\n",
    "# Threshold for Edit Distance\n",
    "EDIT_THRESHOLD = 0\n"
   ],
   "metadata": {
    "id": "TSIR72dHb_ze"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# unzipping files\n",
    "\n",
    "# one drive link to weights, active until 12/22/2023\n",
    "# https://purdue0-my.sharepoint.com/:f:/g/personal/sinha102_purdue_edu/EjeivgmR47xGvWgRJ0X_XF8BPwuSHlF2Gks0xfilKclXaw?e=t1OR5f\n",
    "\n",
    "# extract weights assuming the zip file is present in /content and pwd=/content\n",
    "!unzip -q best_weights_ver5.zip -d model_weights_tmp\n",
    "\n",
    "# make directory for weights\n",
    "!mkdir {MODEL_DIR}\n",
    "!mv /content/model_weights_tmp/content/yolov5/runs/train/step1_train/weights/* {MODEL_DIR}\n",
    "\n",
    "# remove tmp dir\n",
    "!rm -r model_weights_tmp/\n",
    "\n",
    "# unzip grading zip file\n",
    "!unzip -q grading.zip\n",
    "\n",
    "# create result directory\n",
    "!mkdir {RESULT_DIR}\n",
    "\n",
    "# create edit distance directory\n",
    "!mkdir {EDIST_PATH}\n",
    "\n",
    "# create submission directory\n",
    "!mkdir {SUBMIT_PATH}"
   ],
   "metadata": {
    "id": "9_hCJk6ryrff"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Object Detection\n",
    "\n",
    "*   Use a YoloV5 model trained on Collection 1 to detect ERD objects present in all images in GRADING_DIR.\n",
    "*   Crop images and place them in a folder for each sample within PROCESSED_DIR, split by the type of ERD object it is.\n",
    "* Utilizes the object_detection.py script written bu the group.\n",
    "\n"
   ],
   "metadata": {
    "id": "ubZL2Vf4SL8X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Object Detection Step\n",
    "\n",
    "def process_sample(sample_dir: str):\n",
    "    \"\"\"Takes as input the path to a directory and processes it based\n",
    "        on the specifications provided in the assignment\"\"\"\n",
    "\n",
    "    for curr_file in os.listdir(sample_dir):\n",
    "\n",
    "        print(f\"Processing {curr_file=}\")\n",
    "\n",
    "        if not curr_file.endswith('.png'):\n",
    "            continue\n",
    "\n",
    "        !python object_detection.py --weights={MODEL_WEIGHTS} \\\n",
    "        --img_src={os.path.join(sample_dir, curr_file)} \\\n",
    "        --yolo_path={YOLO_PATH} \\\n",
    "        --save_dir={os.path.join(PROCESSED_DIR, sample_dir.split(\"dataset\", 1)[1])} \\\n",
    "        --name={curr_file.rstrip(\".png\")} \\\n",
    "        --yaml_src={YAML_PATH}\n",
    "\n",
    "        print(f\"processed {curr_file}\")\n",
    "\n"
   ],
   "metadata": {
    "id": "U3RxoaKUF8tm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# iterate through all Samples\n",
    "\n",
    "for sample in os.listdir(GRADING_DIR):\n",
    "\n",
    "    print(f\"Processing {sample}\")\n",
    "\n",
    "    process_sample(os.path.join(GRADING_DIR, sample))\n"
   ],
   "metadata": {
    "id": "-bWpLRTFE974"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: OCR\n",
    "\n",
    "*   Use the EasyOCR python package to perform OCR on each sample has been detected and sorted based on ERD objects.\n",
    "*   Results are stored in RESULT_DIR under the file with the namng convetion of SAMPLE.txt, where SAMPLE is the name of the original input image.\n",
    "* Utilizes the text_ocr.py python script written by the group.\n",
    "\n"
   ],
   "metadata": {
    "id": "f9s4hAg3SXTQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# OCR step\n",
    "\n",
    "def process_img_text(dataset_name: str):\n",
    "\n",
    "    !mkdir {os.path.join(RESULT_DIR, dataset_name)}\n",
    "\n",
    "    for curr_image in os.listdir(os.path.join(PROCESSED_DIR, dataset_name)):\n",
    "\n",
    "      # set working directory\n",
    "      WORKING_DIR = os.path.join(PROCESSED_DIR, dataset_name, curr_image, \"cropped\")\n",
    "\n",
    "      # iterate all objects in that image\n",
    "      for object_det in os.listdir(WORKING_DIR):\n",
    "\n",
    "          # iterate through all cropped images of that object\n",
    "          for cropped in os.listdir(os.path.join(WORKING_DIR, object_det)):\n",
    "              # print(os.path.join(RESULT_DIR, dataset_name, curr_image + '.txt'))\n",
    "              !python text_ocr.py \\\n",
    "              --img_path={os.path.join(WORKING_DIR, object_det, cropped)} \\\n",
    "              --save_dir={os.path.join(RESULT_DIR, dataset_name, curr_image + '.txt')} \\\n",
    "              --object_type={object_det} \\\n",
    "              --include_entity={False}\n",
    "\n",
    "          print(f\"Processed {object_det} for img {curr_image}\")"
   ],
   "metadata": {
    "id": "ayJztgQOvCmx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# process all images in each dataset\n",
    "\n",
    "for curr_dataset in os.listdir(PROCESSED_DIR):\n",
    "\n",
    "    process_img_text(curr_dataset)"
   ],
   "metadata": {
    "id": "1bYGz0DRtShW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Edit Distance\n",
    "\n",
    "*   Determines the edit distance between the words detected from the images and the vocabulary present in the question and decided if words need to be modified.\n",
    "* The decision to modify or not depends on the threshold set.\n",
    "* Saves the modified files in SUBMIT_PATH.\n",
    "*   Utilizes the edit_distance.py script written by the team.\n",
    "\n"
   ],
   "metadata": {
    "id": "dm_X_wd_TuSU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Edit distance\n",
    "\n",
    "for dataset in os.listdir(RESULT_DIR):\n",
    "\n",
    "    !mkdir {os.path.join(EDIST_PATH, dataset)}\n",
    "\n",
    "    for res in os.listdir(os.path.join(RESULT_DIR, dataset)):\n",
    "\n",
    "        !python edit_distance.py \\\n",
    "        --objects_file={os.path.join(RESULT_DIR, dataset, res)} \\\n",
    "        --question_path={os.path.join(GRADING_DIR, \"dataset\" + dataset, \"question.txt\")} \\\n",
    "        --output_file={os.path.join(EDIST_PATH, dataset, res)} \\\n",
    "        --threshold={EDIT_THRESHOLD}"
   ],
   "metadata": {
    "id": "ov6vR9Tg2ehF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Module 4\n",
    "\n",
    "*   Run Module 4 to use the baseline clustering method to cluster all entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Baseline clustering\n",
    "\n",
    "def cluster_dataset(dataset: str, k: int):\n",
    "\n",
    "    !python base_line_clustering.py \\\n",
    "    --dataset_dir={os.path.join(EDIST_PATH, dataset)} \\\n",
    "    --output_file={os.path.join(SUBMIT_PATH, f\"base_line_clusters_{dataset}.txt\")} \\\n",
    "    --num_clusters={k}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run for all datasets\n",
    "\n",
    "for dataset in os.listdir(EDIST_PATH):\n",
    "\n",
    "    # get the expected number of clusters\n",
    "    k = int(input(f\"Number of expected clusters for dataset{dataset}: \"))\n",
    "\n",
    "    # cluster the images\n",
    "    cluster_dataset(dataset, k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Store Results\n",
    "\n",
    "*   Zips the final text files in a file with the team name.\n",
    "\n"
   ],
   "metadata": {
    "id": "pwPVgabeWPJg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# zip all results into a file wiht team name for grading\n",
    "%cd {SUBMIT_PATH}\n",
    "!zip /content/hintonians.zip *\n",
    "%cd /content"
   ],
   "metadata": {
    "id": "CUj-Jkjm7om8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}